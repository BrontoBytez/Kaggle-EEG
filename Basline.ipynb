{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Overview\n",
    "\n",
    "Look at change insignal power (spectral features) in the 10 Hz and 20 Hz freq bands in the sensorimotor cortex.\n",
    "    CSP spatial filters trained to enhance signal coming from the brain area. We extract instantaneous power, smooth itand then feed into logistic Reg.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Preprocessing: \n",
    "\n",
    "Band-Pass filtering between 7 and 30 Hz. Then 4 CSP filters applied to signal -> 4 new time series. To train the CSP filters EEG epoched using window of 1.5 seconds before and after the event 'Replace.' CSP training needs 2 classes. Epochs before replace event assumed to contain patterns corresponding to hand movement. Epochs after assumed to contain resting state. We maximize the variance of the signal during hand movement and minimize it during rest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction\n",
    "\n",
    "Preprocessing applied, spatially filtered signal are rectified and convolved with 0.5 second rectangular window for smoothing. Then logarithm applied. Get out a  vector of 4 dimensions for each time sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "\n",
    "For each of the 6 event types logistic regression trained. For training only features downsampled to speed up process. Prediction is probs of the logit reg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import utility and validation modules\n",
    "import utils as utils\n",
    "import validation as validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('numpy: ', '1.9.2')\n",
      "('pandas: ', '0.16.2')\n"
     ]
    }
   ],
   "source": [
    "#install basic Python package and dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "utils.print_version('numpy', np)\n",
    "utils.print_version('pandas', pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Install MNE modules\n",
    "from mne.io import RawArray\n",
    "from mne.channels import read_montage\n",
    "from mne.epochs import concatenate_epochs\n",
    "from mne import create_info, find_events, Epochs, concatenate_raws, pick_types \n",
    "from mne.decoding import CSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Install machine learning and signal processing modules\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.signal import butter, lfilter, convolve, boxcar\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_raw_mne_object(filename, read_events=True):\n",
    "    \"\"\"\n",
    "    Create mne raw instance from csv file\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(filename)\n",
    "    \n",
    "    #Grab channel names\n",
    "    channel_names = list(data.columns[1:]) #all columns\n",
    "    \n",
    "    #Read EEG standard montage (patterns of connection between electrodes; usually 16 or more electrodes)\n",
    "    \"\"\"\n",
    "    Montage means the placement of the electrodes. \n",
    "    The EEG can be monitored with either a bipolar montage or a referential one. \n",
    "    -Bipolar means that you have two electrodes per one channel, so you have a reference electrode for each channel. \n",
    "    -Referential montage means that you have a common reference electrode for all the channels.\n",
    "    \"\"\"\n",
    "    montage = read_montage('standard_1005', channel_names)\n",
    "    \n",
    "    #First is EEG (32 channells)\n",
    "    channel_types = ['eeg']*len(channel_names)\n",
    "    \n",
    "    #scale down to microvolts\n",
    "    data = 1e-6*np.array(data[channel_names]).T\n",
    "    \n",
    "    if read_events:\n",
    "        #get corresponding events_file\n",
    "        events_filename = filename.replace('_data', '_events')\n",
    "        events = pd.read_csv(events_filename)\n",
    "        event_names = events.columns[1:]\n",
    "        events_data = np.array(events[event_names]).T\n",
    "        \n",
    "        #Define channel_types\n",
    "        #First 32 are EEG\n",
    "        #Last 6 are the stimulations\n",
    "        channel_types.extend(['stumulation']*6)\n",
    "        channel_names.extend(event_names)\n",
    "        \n",
    "        #concat data file and events file\n",
    "        data = np.concatenate((data, events_data))\n",
    "        \n",
    "    \n",
    "    #create and populate MNE info structure\n",
    "    mne_info = create_info(channel_names, sfreq=500.0, ch_types=channel_types, montage = montage)\n",
    "    \n",
    "    mne_info['filename'] = filename\n",
    "    \n",
    "    #Make raw array out of mne_info object\n",
    "    raw = RawArray(data, mne_info, verbose = False)\n",
    "    return raw     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def band_pass_filter(raw, picks):\n",
    "    #Low and high cutoff freqs\n",
    "    freqs = [7,30]\n",
    "    #retunrs numerator and denominator polynomials (coefficinets) of the filter\n",
    "    filterOrder = 5\n",
    "    criticalFreqs = np.array(freqs)/250.0\n",
    "    b,a = butter(filterOrder, np.aray(freqs)/250.0, btype='bandpass')\n",
    "    \n",
    "    raw._data[picks] = np.array(Parallel(n_jobs=-1)(delayed(lfilter)(b,a,raw._data[i]) for i in picks))\n",
    "    \n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_epochs(raw_mne, events, picks, stim_channel='Replace'):\n",
    "    #We are just focused on the 'replace' event so get the position corresponding to that\n",
    "    #looks it up in our Raw MNE, first 32 events are EEG readings, last 6 are stimuli\n",
    "    events = find_events(raw_mne, stim_channel, verbose=False)\n",
    "    \n",
    "     #epochs signal for 1.5 seconds before the movement\n",
    "        #will make list of epochs from raw object\n",
    "        #So we are just defining the epochs by their band around the trigger\n",
    "        \"\"\"\n",
    "        raw: instance of raw MNE info\n",
    "        events: events that we care about (here we are focused on replace event)\n",
    "        event_id: id of the event to consider (i think during is how long it lasts which is weird because they should be 2ms)\n",
    "        time_min: startime before the event (2 ms before here)\n",
    "        time_max: endtime after the event(i think this is disallowed in the competition)\n",
    "        proj: whether or not want to apply SSP projection vectors\n",
    "        \"\"\"\n",
    "    epochs = Epochs(raw_mne, events, {'during': 1}, -2, -0.5, proj=False,\n",
    "                   picks = picks, baseline=None, preload=True,\n",
    "                   add_eeg_reg=False, verbose=False)\n",
    "    \n",
    "    epochs_rest = (raw_mne, events, {'after': 1}, 0.5, 2, proj=False,\n",
    "                  add_eeg_ref=False, verbose=False)\n",
    "    \n",
    "    #workaround to be able to concat epochs with MNE\n",
    "    epochs_rest.times = epochs.times\n",
    "    \n",
    "    return epochs, epochs_rest  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rectify_spatially_filtered_signal(raw, csp, picks, num_filters):\n",
    "    feat = np.dot(csp.filters_[0:nfilters], raw._data[picks])\n",
    "    feat = feat**2 #power of 2 (squaring!)\n",
    "    return feat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolve_spatially_filtered_signal(features, csp num_filters):\n",
    "    testing_features = np.array(Parallel(n_jobs=-1)(delayed(convolve)(feat[i], boxcar(nwin),'full') for i in range(nfilters)))\n",
    "    testing_features = np.log(testing_features[:, 0:features.shape[1]])\n",
    "    return testing_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_training_features(raw, csp, picks, num_filters):\n",
    "    features = rectify_spatially_filtered_signal(raw, csp, picks, num_features)\n",
    "    training_features = convolve_spatially_filtered_signal(features, csp, num_features)\n",
    "    return training_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_testing_features(raw, csp, picks, num_filters):\n",
    "    features = rectify_spatially_filtered_signal(raw, csp, picks, num_features)\n",
    "    testing_features = convolve_spatially_filtered_signal(features, csp, num_features)\n",
    "    return testing_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_spatial_features(X, Y, raw_training, raw_testing, picks):\n",
    "    #csp params\n",
    "    reg_method = 'lls'\n",
    "    num_filters = 4\n",
    "    \n",
    "    csp = CSP(n_components=num_filters, reg=reg_method)\n",
    "    csp.fit(X,Y)\n",
    "    \n",
    "    testing_features = make_testing_features(raw_training, csp, picks, num_filters)\n",
    "    training_features = make_training_features(raw_testing, csp, picks, num_filters)\n",
    "    \n",
    "    return training_features, testing_features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_predictions(training_features, test_features, ids, labels):\n",
    "    logit = LogisticRegression()\n",
    "    num_events = 6\n",
    "    predictions = np.empty(len(ids), num_events) #len(ids) by num_events shape\n",
    "    for i in range(num_events):\n",
    "        print('Train subject %d, class %s' % (subject, cols[i]))\n",
    "        logit.fit(training_features[:, ::subsample].T, labels[i, ::subsample])\n",
    "        predictions[:, i] = logit.predict_proba(test_features.T)[:,1]\n",
    "    return predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Parameters for main program\n",
    "subsample_size = 10\n",
    "subjects = range(1,13)\n",
    "total_ids = []\n",
    "total_predictions = []\n",
    "\n",
    "submission_file = './submissions/baseline.csv'\n",
    "events =  ['HandStart','FirstDigitTouch',\n",
    "        'BothStartLoadPhase','LiftOff',\n",
    "        'Replace','BothReleased']\n",
    "stimulus_channel = 'Replace'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Main Program: Perform analysis for each subject\n",
    "for subject in subjects:\n",
    "    total_epochs = []\n",
    "    y = []\n",
    "    \n",
    "    filenames = glob('../input/train/subj%d_series*_data.csv' % (subject))\n",
    "    testing_filenames = glob('../input/train/subj&d_series*_data.csv' & (subject))\n",
    "    \n",
    "    #all the raw mne Arrays concatenated together \n",
    "    raw_training = concatenate_raws([create_raw_mne_object(filename) for filename in filenames] )\n",
    "    raw_testing = concatenate_raws([create_raw_mne_object(filename) for filename in testing_filenames])\n",
    "    \n",
    "    \n",
    "    #pick the channels by type and name\n",
    "    picks = pick_types(raw.info, eeg=True)\n",
    "    \n",
    "    #Filter data for alpha and beta freq bands\n",
    "    #By default MNE does zero phase (filtfilt) filtering which uses future frames\n",
    "    #So do left filter to avoid future leakage\n",
    "    #Parallelized to speed up computations  \n",
    "    raw_training = band_pass_filter(raw_training, picks)\n",
    "    raw_testing = band_pass_filter(raw_testing, picks)\n",
    "    \n",
    "    #Make Epochs and arrange data\n",
    "    epochs, epochs_rest = make_epochs(raw_training, events, picks, stimulus_channel)\n",
    "    total_epochs.append(epochs)\n",
    "    y.extend([1]*len(epochs))\n",
    "    y.extend([-1]*len(epochs_rest))\n",
    "    total_epochs.append(epochs_rest)\n",
    "    \n",
    "    #concat all epochs\n",
    "    epochs = concatenate_epochs(total_epochs)\n",
    "    \n",
    "    #get our data\n",
    "    X = epochs.get_data()\n",
    "    Y = np.array(Y)\n",
    "    \n",
    "    #Makee features with CSP\n",
    "    training_features, testing_features = make_spatial_features(X, Y, raw_training, raw_testing, picks)\n",
    "    \n",
    "    #read ids from testing files\n",
    "    ids = np.concatenate([np.array(pd.read_csv(filename)['id']) for fname in testing_filenames])\n",
    "    total_ids.append(ids)\n",
    "    \n",
    "    #Get training labels (last 6 channels of raw MNE)\n",
    "    labels = raw_testing._data[32:]\n",
    "    \n",
    "    #Train and predict!\n",
    "    predictions = make_predictions(training_features, test_features, ids, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make submission file\n",
    "utils.make_submission_file(filename, total_ids, events, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
