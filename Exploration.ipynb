{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from glob import glob #finds all pathnames matching specified pattern\n",
    "import os \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read Data\n",
    "def prepare_train_data(file_name):\n",
    "    \"\"\"Read and prepare training data\"\"\"\n",
    "    data = pd.read_csv(file_name)\n",
    "    #events file\n",
    "    events_fname = file_name.replace('_data', '_events')\n",
    "    #read event file\n",
    "    labels = pd.read_csv(events_fname)\n",
    "    clean = data.drop(['id'], axis=1) # remove id\n",
    "    labels = labels.drop(['id'], axis=1)\n",
    "    return clean, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepare_test_data(file_name):\n",
    "    \"\"\"Read and prepare test data\"\"\"\n",
    "    data = pd.read_csv(file_name)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_training_data(X):\n",
    "    X_prep = scaler.fit_transform(X) #computes mean, sd and then transforms\n",
    "    #Do any other preprocessing here beyonf standardizing\n",
    "    return X_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_testing_data(X):\n",
    "    X_prep=scaler.transform(X)\n",
    "    #do here your preprocessing\n",
    "    return X_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Num Subjects\n",
    "subjects = range(1, 2)\n",
    "ids_total = []\n",
    "predicted_total = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training subsample.if want to downsample the training data\n",
    "subsample = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Standardize features by removing mean and scaling to unit variance\n",
    "scaler = StandardScaler() #just prepares for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#column names for labels\n",
    "labels = ['HandStart','FirstDigitTouch','BothStartLoadPhase','LiftOff','Replace','BothReleased']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#loop over subjects and 8 series for training data + 2 series for test data\n",
    "for subject in subjects:\n",
    "    raw_labels = []\n",
    "    raw_data = []\n",
    "    \n",
    "    #Read Training Data\n",
    "    fnames = glob('./data/train/subj%d_series*_data.csv' % (subject))\n",
    "    for fname in fnames:\n",
    "        data, labels = prepare_train_data(fname)\n",
    "        raw_data.append(data)\n",
    "        raw_labels.append(labels)\n",
    "        \n",
    "    X = pd.concat(raw_data)\n",
    "    Y = pd.concat(raw_labels)\n",
    "    \n",
    "    #Read Test Data\n",
    "    fnames = glob('./data/test/subj%d_series*_data.csv' % (subject))\n",
    "    test = []\n",
    "    idx = []\n",
    "    for fname in fnames:\n",
    "        data = prepare_test_data(fname)\n",
    "        test.append(data)\n",
    "        idx.append(np.array(data['id']))\n",
    "    X_test = pd.concat(test)\n",
    "    ids = np.concatenate(idx)\n",
    "    ids_total.append(ids)\n",
    "    X_test = X_test.drop(['id'], axis=1) #remove id\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Form into numpy array and transform to floats\n",
    "X_train  = np.asarray(X.astype(float))\n",
    "Y_train = np.asarray(Y.astype(float))\n",
    "X_test = np.asarray(X_test.astype(float))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1422392, 32)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "#1422392 rows are the 30 trials for 8 series for (1) subject with a sampling rate at 500 Hz (500 samples per second)\n",
    "# or 1 sample every 2 ms (also meaning a sample lasts 2 ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1422392, 6)\n"
     ]
    }
   ],
   "source": [
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Train Classifiers\n",
    "logReg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler= StandardScaler()\n",
    "predicted = np.empty((X_test.shape[0], len(labels)))\n",
    "X_train = preprocess_training_data(X_train)\n",
    "X_test = preprocess_testing_data(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train subject 1, class HandStart\n",
      "Train subject 1, class FirstDigitTouch\n",
      "Train subject 1, class BothStartLoadPhase\n",
      "Train subject 1, class LiftOff\n",
      "Train subject 1, class Replace\n",
      "Train subject 1, class BothReleased\n"
     ]
    }
   ],
   "source": [
    "for subject in subjects:\n",
    "    for i in range(len(labels)):\n",
    "        y_train = Y_train[:,i]\n",
    "        print('Train subject %d, class %s' % (subject, labels[i]))\n",
    "        logReg.fit(X_train[::subsample, :], y_train[::subsample])\n",
    "        predicted[:,i] = logReg.predict_proba(X_test)[:,1]\n",
    "    \n",
    "        predicted_total.append(predicted)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(predicted_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Output file\n",
    "output = 'exploration.csv'\n",
    "submission = pd.DataFrame(index=np.concatenate(ids_tot), columns=labels, data=np.concatenate(predicted_total))\n",
    "\n",
    "#write file\n",
    "submission.to.csv(output, index_label='id', float_format='%.3f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
